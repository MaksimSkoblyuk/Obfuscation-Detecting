{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e25d2d2b",
   "metadata": {},
   "source": [
    "# Предобработка команд PowerShell с помощью утилиты Revoke-Obfuscation для обучения моделей/классификации\n",
    "\n",
    "- Исходный код утилиты доступен на GitHub по [ссылке](https://github.com/danielbohannon/Revoke-Obfuscation)\n",
    "- Некоторые необходимые данные можно скачать из облака по [ссылке](https://drive.google.com/drive/folders/1TN4UM1v2XJUxkAhCQxKBge_TsyY9FgCs?usp=drive_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f097973",
   "metadata": {},
   "source": [
    "## Инструкция по настройке:\n",
    "\n",
    "- Необходимо установить `PowerShell` (7.x версии и выше)\n",
    "- Необходимо установить `dotnet` (6.0 версии)\n",
    "- Необходимо установить `PSFeatureExtractorLibrary.zip` и `pspython.runtimeconfig.json` из облака\n",
    "- Необходимо скачать файл `drop_features.txt` из облака, содержащий признаки, которые необходимо удалить\n",
    "\n",
    "*Если версия `dotnet` отличается, то необходимо:*\n",
    "1. пересобрать DLL библиотеку, содержащую методы Revoke-Obfuscation\n",
    "2. поменять конфигурационные данные в файле `pspython.runtimeconfig.json`\n",
    "\n",
    "*Исходные используемые классы Revoke-Obfuscation доступны в облаке в архиве `Revoke-Obfuscation_source-code.zip`*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d6d1b2",
   "metadata": {},
   "source": [
    "## Инструкция по использованию:\n",
    "\n",
    "- Для обучения моделей ожидается CSV файл, построчно содержащий команду PowerShell и результат её классификации (header отсутствует, то есть сразу идут строки в формате '<команда PowerShell>,<обфусцированность (0 или 1)>')\n",
    "- Для классификации ожидается TXT файл, построчно содержащий команды PowerShell\n",
    "- На выходе получается предобработанный набор данных (CSV файл), содержащий 2709 признаков, среди которых для обучения признак `obfuscated` является целевым, я для классификации признак `command` содержит команду PowerShell до предобработки\n",
    "\n",
    "*При необходимости редактируйте ноутбук под свои условия*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb786461",
   "metadata": {},
   "source": [
    "### 1. Настройка и подключение утилиты Revoke-Obfuscation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c958941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "\n",
    "import pythonnet\n",
    "import clr_loader\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b467390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotnet_path = r\"<путь до dotnet>\"\n",
    "powershell_path = r\"<путь до PowerShell>\"\n",
    "config_file_path = r\"<путь до pspython.runtimeconfig.json>\"\n",
    "ps_features_extractor_library_path = r\"<путь до PSFeatureExtractorLibrary> (net6.0 из архива или перегенерированное решение)\"\n",
    "\n",
    "microsoft_management_infrastructure_dll_path = fr\"{powershell_path}\\Microsoft.Management.Infrastructure.dll\"\n",
    "system_management_automation_dll_path = fr\"{powershell_path}\\System.Management.Automation.dll\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa55c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"DOTNET_ROOT\"] = dotnet_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a08d514",
   "metadata": {},
   "outputs": [],
   "source": [
    "coreclr = clr_loader.get_coreclr(runtime_config=config_file_path)\n",
    "pythonnet.set_runtime(coreclr)\n",
    "pythonnet.get_runtime_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09082ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clr\n",
    "import System\n",
    "\n",
    "clr.AddReference(microsoft_management_infrastructure_dll_path)\n",
    "clr.AddReference(system_management_automation_dll_path)\n",
    "\n",
    "# test adding references\n",
    "# import Microsoft.Management.Infrastructure\n",
    "# import System.Management.Automation.Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa0a7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(ps_features_extractor_library_path)\n",
    "clr.AddReference(\"PSFeatureExtractorLibrary\")\n",
    "\n",
    "# test adding reference\n",
    "# import PSFeatureExtractorLibrary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f7b990",
   "metadata": {},
   "source": [
    "### 2. Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2954e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PSFeatureExtractorLibrary\n",
    "\n",
    "METHODS = [\n",
    "    PSFeatureExtractorLibrary.GroupedArrayElementRangeCounts.AnalyzeAst,\n",
    "    PSFeatureExtractorLibrary.ArrayElementMetrics.AnalyzeAst,\n",
    "    PSFeatureExtractorLibrary.GroupedAssignmentStatements.AnalyzeAst,\n",
    "    PSFeatureExtractorLibrary.GroupedAstTypes.AnalyzeAst,\n",
    "    PSFeatureExtractorLibrary.GroupedBinaryExpressionOperators.AnalyzeAst,\n",
    "    PSFeatureExtractorLibrary.CmdletMetrics.AnalyzeAst,\n",
    "    PSFeatureExtractorLibrary.CommandParameterNameMetrics.AnalyzeAst,\n",
    "    PSFeatureExtractorLibrary.CommentMetrics.AnalyzeAst,\n",
    "    PSFeatureExtractorLibrary.ConvertExpressionMetrics.AnalyzeAst,\n",
    "    PSFeatureExtractorLibrary.FunctionNameMetrics.AnalyzeAst,\n",
    "    PSFeatureExtractorLibrary.IntegerAndDoubleMetrics.AnalyzeAst,\n",
    "    PSFeatureExtractorLibrary.InvocationOperatorInvokedObjectMetrics.AnalyzeAst,\n",
    "    PSFeatureExtractorLibrary.LineByLineMetrics.AnalyzeAst,\n",
    "    PSFeatureExtractorLibrary.MemberArgumentMetrics.AnalyzeAst,\n",
    "    PSFeatureExtractorLibrary.MemberMetrics.AnalyzeAst,\n",
    "    PSFeatureExtractorLibrary.StringMetrics.AnalyzeAst,\n",
    "    PSFeatureExtractorLibrary.TypeConstraintMetrics.AnalyzeAst,\n",
    "    PSFeatureExtractorLibrary.TypeExpressionMetrics.AnalyzeAst,\n",
    "    PSFeatureExtractorLibrary.GroupedUnaryExpressionOperators.AnalyzeAst,\n",
    "    PSFeatureExtractorLibrary.VariableNameMetrics.AnalyzeAst\n",
    "]\n",
    "\n",
    "FEATURES_PER_METHOD = [22, 312, 14, 152, 104, 312, 312, 312, 312, 312, 312, 312, 312, 312, 312, 312, 312, 312, 26, 312]\n",
    "CUMULATIVE_FEATURES = np.cumsum(FEATURES_PER_METHOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc19e9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_without_features(command: str, methods: list, cumulative_features: list[int]) -> list[float]:\n",
    "    ast, token, parsing_error = System.Management.Automation.Language.Parser.ParseInput(command)\n",
    "    \n",
    "    if parsing_error:\n",
    "        raise ValueError(parsing_error)\n",
    "    \n",
    "    tokenized_values = np.zeros(cumulative_features[-1], dtype=\"float64\")\n",
    "    \n",
    "    left_index = 0\n",
    "    for i in range(len(methods)):\n",
    "        right_index = cumulative_features[i]\n",
    "        tokenized_values[left_index:right_index] = list(methods[i](ast).Values)\n",
    "        left_index = right_index\n",
    "\n",
    "    return list(tokenized_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1147c56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_with_features(command: str, methods: list, cumulative_features: list[int]) -> dict[str, list]:\n",
    "    ast, token, parsing_error = System.Management.Automation.Language.Parser.ParseInput(command)\n",
    "    \n",
    "    if parsing_error:\n",
    "        raise ValueError(parsing_error)\n",
    "        \n",
    "    tokenized_values = np.zeros(cumulative_features[-1], dtype=\"float64\")\n",
    "    features = [''] * cumulative_features[-1]\n",
    "    \n",
    "    left_index = 0\n",
    "    for i in range(len(methods)):\n",
    "        right_index = cumulative_features[i]\n",
    "        ast_analysis = methods[i](ast)\n",
    "        tokenized_values[left_index:right_index] = list(ast_analysis.Values)\n",
    "        features[left_index:right_index] = list(ast_analysis.Keys)\n",
    "        left_index = right_index\n",
    "\n",
    "    return {\"features\": features, \"values\": list(tokenized_values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c33d7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(commands: list[str]) -> tuple[pd.DataFrame, list[str]]:\n",
    "    dataframe = pd.DataFrame()\n",
    "    \n",
    "    count = 0\n",
    "    tokenized_commands = []\n",
    "    for command in commands:\n",
    "        try:\n",
    "            if not count:\n",
    "                tokenized_result = tokenize_with_features(command=command, methods=METHODS, cumulative_features=CUMULATIVE_FEATURES)\n",
    "                dataframe = pd.concat([dataframe, pd.DataFrame(columns=tokenized_result[\"features\"])], ignore_index=True)\n",
    "                dataframe.loc[len(dataframe)] = tokenized_result[\"values\"]\n",
    "            else:\n",
    "                dataframe.loc[len(dataframe)] = tokenize_without_features(command=command, methods=METHODS, cumulative_features=CUMULATIVE_FEATURES)\n",
    "            count += 1\n",
    "            if not count % 500:\n",
    "                print(f\"{count} commands tokenized successfully\\n\")\n",
    "            tokenized_commands.append(command)\n",
    "        except Exception as e:\n",
    "            print(f\"For command {command!r} error occurred while tokenizing: {e}\\n\")\n",
    "    return dataframe, tokenized_commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee56e9e1",
   "metadata": {},
   "source": [
    "### 3. Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd87ecc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(dataframe: pd.DataFrame, columns: list[str]) -> pd.DataFrame:\n",
    "    return dataframe.drop(labels=columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd78025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_column(dataframe: pd.DataFrame, column_name: str, values: list) -> pd.DataFrame:\n",
    "    dataframe[column_name] = values\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81db219a",
   "metadata": {},
   "source": [
    "### 4. Считывание данных из файла\n",
    "\n",
    "- для получения команд перед классификацией\n",
    "- для получения признаков, которые нужно исключить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46112233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt_file(filename: str) -> list[str]:\n",
    "    with open(file=filename, mode='r') as file:\n",
    "        return [row for row in file.read().split('\\n') if row]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17776ed7",
   "metadata": {},
   "source": [
    "### 5. Считывание исходных данных, токенизация, предобработка и сохранение полученных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192bbf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96c5ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_training(dataframe: pd.DataFrame, features_to_drop_path: str) -> pd.DataFrame:\n",
    "    if len(dataframe) < 2:\n",
    "        raise ValueError(f\"Input data must contains at least 2 commands\")\n",
    "    commands = dataframe.iloc[:, 0]\n",
    "    y = dataframe.iloc[:, 1]\n",
    "    tokenized_dataframe, _ = tokenize(commands=commands)\n",
    "    features_to_drop = read_txt_file(filename=features_to_drop_path)\n",
    "    balanced_dataframe = drop_columns(dataframe=tokenized_dataframe, columns=features_to_drop)\n",
    "    normalized_dataframe = pd.DataFrame(MinMaxScaler().fit_transform(balanced_dataframe), columns=balanced_dataframe.columns)\n",
    "    return add_column(dataframe=normalized_dataframe, column_name=\"obfuscated\", values=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61fbe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_classification(commands: list[str], features_to_drop_path: str) -> pd.DataFrame:\n",
    "    if len(commands) < 2:\n",
    "        raise ValueError(f\"Input data must contains at least 2 commands\")\n",
    "    tokenized_dataframe, tokenized_commands = tokenize(commands=commands)\n",
    "    features_to_drop = read_txt_file(filename=features_to_drop_path)\n",
    "    balanced_dataframe = drop_columns(dataframe=tokenized_dataframe, columns=features_to_drop)\n",
    "    normalized_dataframe = pd.DataFrame(MinMaxScaler().fit_transform(balanced_dataframe), columns=balanced_dataframe.columns)\n",
    "    return add_column(dataframe=normalized_dataframe, column_name=\"command\", values=tokenized_commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c48e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop_path = r\"<путь до файла drop_features.txt>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efa303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобработка для обучения\n",
    "source_filename = r\"<путь до исходного *.csv файла с командами PowerShell и значениями их обфусцированности для обучения моделей>\"\n",
    "target_filename = r\"<путь до *.csv файла, куда будет сохранен результат предобработки>\"\n",
    "\n",
    "source_dataframe = pd.read_csv(filepath_or_buffer=source_filename, header=None)\n",
    "preprocessed_dataframe = preprocess_for_training(dataframe=source_dataframe, features_to_drop_path=features_to_drop_path)\n",
    "preprocessed_dataframe.to_csv(target_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a46339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобработка для классификации\n",
    "source_filename = r\"<путь до исходного *.txt файла с командами PowerShell для классификации>\"\n",
    "target_filename = r\"<путь до *.csv файла, куда будет сохранен результат предобработки>\"\n",
    "\n",
    "commands = read_txt_file(filename=source_filename)\n",
    "preprocessed_dataframe = preprocess_for_classification(commands=commands, features_to_drop_path=features_to_drop_path)\n",
    "preprocessed_dataframe.to_csv(target_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bcdfd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
